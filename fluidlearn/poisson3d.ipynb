{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Author: Manu Jayadharan, University of Pittsburgh, 2020__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2: Using fluidlearn to solve an elliptic pde: 3d Poission equation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This is the second example in the series, intended to act as tutorial for fluidlearn package. \n",
    "- New in this example: how to use one of in-built PDE models. We illustrate this by using the _Poisson_ model from the fluidlearn.fluidmodels module. \n",
    "- We also show how to manufacture boundary conditions easily using the fluidlearn.dataprocess module, for convergence testing and debugging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equation to solve: $-\\Delta u -f  = 0$\n",
    "over domain $\\Omega$ ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For demonstration purposes we take $f=-6(x_1 + x_2) - 2$ and $\\Omega = [-2,4]\\times [0,5]\\times [-3,3]$, so we can compare the results with the actual solution $u=x_1^3 + x_2^3 + x_3^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import fluidlearn package and classes\n",
    "import fluidlearn\n",
    "from fluidlearn import dataprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the domain and time interval for which the PDE needs to be solved.\n",
    "This matters only for generating collocation points and if the user is feeding their own collocation points,\n",
    "they can skip this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#domain range\n",
    "X_1_domain = [-1, 1]\n",
    "X_2_domain = [-1, 1]\n",
    "X_3_domain = [-1,1]\n",
    "\n",
    "#domain of the problem\n",
    "domain_bounds = [X_1_domain, X_2_domain, X_3_domain]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manufacturing the boundary data\n",
    "- We use the fluidlearn.dataprocess.BcIcManufact class to generate points lying on the faces of the hypercube defined by the intervals given in domain_bounds. This is equivalent to randomly selecting points from the domain boundary, $\\partial \\Omega$.\n",
    "- We then use our knowledge of the manufactured solution to manufacture the boundary conditions corresponding to these points.\n",
    "- Note that for this example, we use uniform distribution to randomly select points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_data_size = 1000 #number of data points on boundary\n",
    "\n",
    "#object to randomly generate points lying on the boundary\n",
    "bc_generator = dataprocess.BcIcDataManufact(domain_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = bc_generator.generate_uniform_bc_ic(bc_data_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Note that we will have bc_data_size number of instances for each boundary\n",
    "#face\n",
    "X_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating the boundary condition from random boundary points using the manufactured solution $u=x_1^3 + x_2^3 + x_3^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "Y_data = (X_data[:,0]**3 + X_data[:,1]**3 + X_data[:,2]**2)[:,np.newaxis]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.04021596 -0.26791829 -0.50201533 -0.35871264]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.04021596],\n",
       "       [-0.26791829],\n",
       "       [-0.50201533],\n",
       "       [-0.35871264]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_data[0:4,0]**3 + X_data[0:4,1]**3 + X_data[0:4,2]**2)\n",
    "Y_data[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the rhs function $f=-6(x_1 + x_2) - 2$ of the PDE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rhs_function (args, time_dep=False):\n",
    "        return -6*(args[0]+args[1]) -2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data[0:4,:].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'poisson'\n",
    "space_dim = 3 #dimension of Omega\n",
    "time_dependent_problem = False\n",
    "n_hid_lay=3 #numberof hidden layers in the neural network\n",
    "n_hid_nrn=20 #number of neurons in each hidden layer\n",
    "act_func='tanh' #activation function used for hidden layers:  could be elu, relu, sigmoid\n",
    "loss_list='mse' #type of error function used for cost functin, we use mean squared error.\n",
    "optimizer='adam' #type of optimizer for cost function minimization\n",
    "dom_bounds=domain_bounds #domain bounds where collocation points has to be generated\n",
    "\n",
    "distribution = 'uniform' #type of distribution used for generating the pde collocation points.\n",
    "number_of_collocation_points = 10000\n",
    "\n",
    "batch_size = 32 #batch size for stochastic batch gradient type optimization\n",
    "num_epochs = 10 #number of epochs used for trainng  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the fluidlearn solver "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiation of the fluidlearn.fluildlearn.Solver class\n",
    "poisson3d_model = fluidlearn.Solver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "poisson3d_model(model_type=model_type,\n",
    "            space_dim=space_dim,\n",
    "            time_dep=time_dependent_problem,\n",
    "            output_dim=1,\n",
    "            n_hid_lay=n_hid_lay,\n",
    "            n_hid_nrn=n_hid_lay,\n",
    "            act_func=act_func,\n",
    "            rhs_func=rhs_function,\n",
    "            loss_list=loss_list,\n",
    "            optimizer=optimizer,\n",
    "            dom_bounds=dom_bounds,\n",
    "            load_model=False,\n",
    "            model_path=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 2.4524 - output_1_loss: 1.1554 - output_2_loss: 1.2971\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 2.1860 - output_1_loss: 1.0135 - output_2_loss: 1.1725\n",
      "Epoch 3/10\n",
      "183/500 [=========>....................] - ETA: 2s - loss: 1.9933 - output_1_loss: 0.9217 - output_2_loss: 1.0716"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-acabd226d34b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m poisson3d_model.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mcolloc_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumber_of_collocation_points\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdistribution\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git-repositories/FluidLearn/fluidlearn/fluidlearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, x_val, y_val, validation, colloc_points, dist, batch_size, epochs)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;31m#fitting model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mY_tr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_tr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1659\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \"\"\"\n\u001b[0;32m-> 1661\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1662\u001b[0m         (t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    591\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    594\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "poisson3d_model.fit(\n",
    "    x=X_data,\n",
    "    y=Y_data,\n",
    "    colloc_points=number_of_collocation_points,\n",
    "    dist=distribution,\n",
    "    batch_size=batch_size,\n",
    "    epochs=num_epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resuming Training  the model again for 50 more epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 671.8516 - output_1_loss: 415.1599 - output_2_loss: 256.6917\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 653.8682 - output_1_loss: 402.1842 - output_2_loss: 251.6844\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 634.7609 - output_1_loss: 388.9823 - output_2_loss: 245.7783\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 615.6924 - output_1_loss: 378.9070 - output_2_loss: 236.7856\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 4s 9ms/step - loss: 596.2515 - output_1_loss: 369.2776 - output_2_loss: 226.9734\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 576.6564 - output_1_loss: 360.9432 - output_2_loss: 215.7130\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 4s 9ms/step - loss: 552.8809 - output_1_loss: 358.6661 - output_2_loss: 194.2148\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 5s 9ms/step - loss: 527.5932 - output_1_loss: 360.3034 - output_2_loss: 167.2897\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 5s 9ms/step - loss: 504.7729 - output_1_loss: 353.4513 - output_2_loss: 151.3217\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 485.0233 - output_1_loss: 346.4853 - output_2_loss: 138.5380\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 4s 9ms/step - loss: 468.0956 - output_1_loss: 334.4396 - output_2_loss: 133.6559\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 4s 9ms/step - loss: 451.9250 - output_1_loss: 319.8982 - output_2_loss: 132.0268\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - 5s 9ms/step - loss: 435.1508 - output_1_loss: 309.6990 - output_2_loss: 125.4519\n",
      "Epoch 14/50\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 420.1669 - output_1_loss: 300.4701 - output_2_loss: 119.6966\n",
      "Epoch 15/50\n",
      "500/500 [==============================] - 5s 9ms/step - loss: 405.4768 - output_1_loss: 287.7364 - output_2_loss: 117.7403\n",
      "Epoch 16/50\n",
      "500/500 [==============================] - 5s 9ms/step - loss: 391.5569 - output_1_loss: 276.9469 - output_2_loss: 114.6103\n",
      "Epoch 17/50\n",
      "500/500 [==============================] - 5s 9ms/step - loss: 376.3559 - output_1_loss: 266.7486 - output_2_loss: 109.6072\n",
      "Epoch 18/50\n",
      "500/500 [==============================] - 5s 9ms/step - loss: 363.9453 - output_1_loss: 258.5280 - output_2_loss: 105.4173\n",
      "Epoch 19/50\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 351.5431 - output_1_loss: 248.8659 - output_2_loss: 102.6772\n",
      "Epoch 20/50\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 337.7137 - output_1_loss: 239.8745 - output_2_loss: 97.8393\n",
      "Epoch 21/50\n",
      "500/500 [==============================] - 4s 9ms/step - loss: 326.1463 - output_1_loss: 229.8026 - output_2_loss: 96.3436\n",
      "Epoch 22/50\n",
      "500/500 [==============================] - 4s 9ms/step - loss: 314.2245 - output_1_loss: 222.4086 - output_2_loss: 91.8160\n",
      "Epoch 23/50\n",
      "500/500 [==============================] - 4s 9ms/step - loss: 302.4311 - output_1_loss: 212.7301 - output_2_loss: 89.7011\n",
      "Epoch 24/50\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 290.3296 - output_1_loss: 204.8875 - output_2_loss: 85.4423\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 280.4311 - output_1_loss: 198.3528 - output_2_loss: 82.0781\n",
      "Epoch 26/50\n",
      "500/500 [==============================] - 5s 9ms/step - loss: 268.1885 - output_1_loss: 188.1268 - output_2_loss: 80.0618\n",
      "Epoch 27/50\n",
      "500/500 [==============================] - 5s 9ms/step - loss: 258.6760 - output_1_loss: 181.3887 - output_2_loss: 77.2872\n",
      "Epoch 28/50\n",
      "500/500 [==============================] - 4s 9ms/step - loss: 248.6503 - output_1_loss: 173.6145 - output_2_loss: 75.0357\n",
      "Epoch 29/50\n",
      "500/500 [==============================] - 5s 9ms/step - loss: 238.4048 - output_1_loss: 166.9805 - output_2_loss: 71.4240\n",
      "Epoch 30/50\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 228.8366 - output_1_loss: 159.7961 - output_2_loss: 69.0404\n",
      "Epoch 31/50\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 219.9278 - output_1_loss: 153.1026 - output_2_loss: 66.8253\n",
      "Epoch 32/50\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 211.1026 - output_1_loss: 146.9844 - output_2_loss: 64.1183\n",
      "Epoch 33/50\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 202.0629 - output_1_loss: 140.8907 - output_2_loss: 61.1721\n",
      "Epoch 34/50\n",
      "500/500 [==============================] - 5s 9ms/step - loss: 194.2753 - output_1_loss: 134.3861 - output_2_loss: 59.8891\n",
      "Epoch 35/50\n",
      "500/500 [==============================] - 5s 9ms/step - loss: 185.0141 - output_1_loss: 127.9451 - output_2_loss: 57.0689\n",
      "Epoch 36/50\n",
      "500/500 [==============================] - 5s 11ms/step - loss: 177.6883 - output_1_loss: 122.8792 - output_2_loss: 54.8092\n",
      "Epoch 37/50\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 171.1705 - output_1_loss: 117.4293 - output_2_loss: 53.7412\n",
      "Epoch 38/50\n",
      "500/500 [==============================] - 6s 11ms/step - loss: 162.4502 - output_1_loss: 110.6859 - output_2_loss: 51.7643\n",
      "Epoch 39/50\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 155.8813 - output_1_loss: 105.8804 - output_2_loss: 50.0010\n",
      "Epoch 40/50\n",
      "500/500 [==============================] - 6s 11ms/step - loss: 149.4420 - output_1_loss: 100.8995 - output_2_loss: 48.5425\n",
      "Epoch 41/50\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 143.6301 - output_1_loss: 95.9291 - output_2_loss: 47.7010\n",
      "Epoch 42/50\n",
      "500/500 [==============================] - 6s 12ms/step - loss: 137.2384 - output_1_loss: 91.6108 - output_2_loss: 45.6276\n",
      "Epoch 43/50\n",
      "500/500 [==============================] - 6s 12ms/step - loss: 130.7300 - output_1_loss: 86.6778 - output_2_loss: 44.0521\n",
      "Epoch 44/50\n",
      "500/500 [==============================] - 6s 12ms/step - loss: 125.3721 - output_1_loss: 82.5785 - output_2_loss: 42.7937\n",
      "Epoch 45/50\n",
      "500/500 [==============================] - 6s 12ms/step - loss: 120.5095 - output_1_loss: 78.5257 - output_2_loss: 41.9838\n",
      "Epoch 46/50\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 113.2191 - output_1_loss: 73.1908 - output_2_loss: 40.0283\n",
      "Epoch 47/50\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 108.9454 - output_1_loss: 69.8212 - output_2_loss: 39.1242\n",
      "Epoch 48/50\n",
      "500/500 [==============================] - 5s 11ms/step - loss: 103.3613 - output_1_loss: 65.5802 - output_2_loss: 37.7811\n",
      "Epoch 49/50\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 98.4330 - output_1_loss: 63.2319 - output_2_loss: 35.2011\n",
      "Epoch 50/50\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 94.6823 - output_1_loss: 59.2641 - output_2_loss: 35.4182\n"
     ]
    }
   ],
   "source": [
    "poisson3d_model.fit(\n",
    "    x=X_data,\n",
    "    y=Y_data,\n",
    "    colloc_points=number_of_collocation_points,\n",
    "    dist=distribution,\n",
    "    batch_size=batch_size,\n",
    "    epochs=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo Using the trained model for predicton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking two points from the domain for time t=0.3 and t=0.76 respectively\n",
    "x_test_points = [[-0.5,0.1,0.3],\n",
    "                [0.66,0.6,0.76]]\n",
    "#Predicting the value\n",
    "y_predicted = poisson3d_model.predict(x_test_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the true y value for comparing\n",
    "import numpy as np\n",
    "x_test_points = np.array(x_test_points)\n",
    "y_true = np.sin(x_test_points[:,0:1] + x_test_points[:,1:2]) * x_test_points[:,2:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#looking at predicted and true solution side by side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.1297535 , -0.1168255 ],\n",
       "       [ 0.70116615,  0.72358866]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate([y_predicted, y_true], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we need more training for further improving the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model to a specified location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\manuj\\anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\manuj\\anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: saved_model/model_name\\assets\n"
     ]
    }
   ],
   "source": [
    "path_to_save_model = \"saved_model/model_name\"\n",
    "poisson3d_model.save_model(path_to_save_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the saved model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_load_model = \"saved_model/model_name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_poisson3d_model = fluidlearn.Solver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_poisson3d_model(space_dim=2,\n",
    "    time_dep=True,\n",
    "    load_model=True,\n",
    "    model_path=path_to_load_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting using loaded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = loaded_poisson3d_model.predict(X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.10157388],\n",
       "       [-0.4190994 ],\n",
       "       [-0.7965628 ],\n",
       "       ...,\n",
       "       [-0.10375804],\n",
       "       [ 0.05802408],\n",
       "       [-0.00470909]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
